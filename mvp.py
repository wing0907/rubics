# =========================================================
# Rubics MVP - ëª¨ë°”ì¼ í•™ìŠµ AI ì–´ì‹œìŠ¤í„´íŠ¸
# =========================================================
# ì‹¬í”Œí•œ ì´ë¯¸ì§€ ì§ˆë¬¸ AI ë‹µë³€ ì„œë¹„ìŠ¤
#
# ê¸°ëŠ¥:
# 1. ì´ë¯¸ì§€ ì—…ë¡œë“œ â†’ ì¦‰ì‹œ AI ë¶„ì„
# 2. ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ
# 3. í•™ìŠµ ë‚´ìš© ìš”ì•½
#
# UI: Claude ìŠ¤íƒ€ì¼ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
# =========================================================

import sys
import subprocess
from pathlib import Path
import os
import json
from datetime import datetime, timedelta
import numpy as np
import pandas as pd
from typing import List, Dict, Optional
from PIL import Image
import io

# ===== ë³´ì•ˆ: API Key ê´€ë¦¬ =====
import streamlit as st

# API Key ìš°ì„ ìˆœìœ„: 1. Streamlit Secrets (í´ë¼ìš°ë“œ) > 2. í™˜ê²½ë³€ìˆ˜ (ë¡œì»¬)
def get_secure_api_key():
    """ë³´ì•ˆ ê°•í™”: API Key ë¡œë“œ (Streamlit Secrets ìš°ì„ )"""
    try:
        if "gemini_api_key" in st.secrets:
            return st.secrets["gemini_api_key"]
    except:
        pass
    
    # ë¡œì»¬ ê°œë°œìš© (í”„ë¡œë•ì…˜ì—ì„œëŠ” ì‚¬ìš© ì•ˆ í•¨)
    if os.getenv("GEMINI_API_KEY_wj"):
        return os.getenv("GEMINI_API_KEY_wj")
    
    return None

GEMINI_API_KEY = get_secure_api_key()

# ===== íŒ¨í‚¤ì§€ ì„¤ì¹˜ =====
packages_needed = []
try:
    import google.generativeai as genai
except:
    packages_needed.append("google-generativeai")
try:
    import cv2
except:
    packages_needed.append("opencv-python")
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
except:
    packages_needed.append("scikit-learn")

if packages_needed:
    cmd = [sys.executable, "-m", "pip", "install", "-q"] + packages_needed
    try:
        subprocess.check_call(cmd)
    except:
        pass

import google.generativeai as genai
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ===== ì„¤ì • =====
GEMINI_MODEL = "gemini-2.0-flash"
OUTPUT_DIR = Path(r"D:\Users\ì¥ìš°ì§„\dev26\qube_out_mvp")
OUTPUT_DIR.mkdir(exist_ok=True)

# Gemini ì´ˆê¸°í™”
if GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
    except Exception as e:
        st.error(f"âŒ Gemini ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

# ===== ë°ì´í„° ë¡œë” =====
@st.cache_resource
def load_master_answers():
    """ë§ˆìŠ¤í„° ë‹µë³€ ë°ì´í„° ë¡œë“œ (ìºì‹±)"""
    try:
        data_dir = Path(r"D:\Users\Qube\0. ë°ì´í„°\1. ë¶„ì„\ë°ì´í„°ë¶„ì„_ìµœì¢…\decoded_messages")
        if not data_dir.exists():
            return []
        
        all_data = []
        for csv_file in sorted(data_dir.glob("*.csv")):
            df = pd.read_csv(csv_file, encoding='utf-8-sig')
            all_data.append(df)
        
        if not all_data:
            return []
        
        df_combined = pd.concat(all_data, ignore_index=True)
        
        # ë§ˆìŠ¤í„° ë‹µë³€ë§Œ ì¶”ì¶œ
        master_data = df_combined[df_combined['speaker_role'] == 'master'].copy()
        master_data = master_data[['QM_QST_NO', 'content', 'DomName']].dropna()
        
        problems = []
        for idx, row in master_data.iterrows():
            problems.append({
                'id': str(row['QM_QST_NO']),
                'answer': str(row['content']),
                'domain': str(row['DomName'])
            })
        
        return problems
    except Exception as e:
        st.warning(f"âš ï¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []

# ===== ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰ =====
@st.cache_resource
def build_problem_index(problems):
    """TF-IDF ì¸ë±ìŠ¤ êµ¬ì¶•"""
    if not problems:
        return None, None
    
    texts = [p['answer'] for p in problems]
    vectorizer = TfidfVectorizer(max_features=200, min_df=1)
    
    try:
        tfidf_matrix = vectorizer.fit_transform(texts)
        return vectorizer, tfidf_matrix
    except:
        return None, None

def search_similar_problems(query, problems, vectorizer, tfidf_matrix, top_k=3):
    """ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰"""
    if not vectorizer or tfidf_matrix is None:
        return []
    
    try:
        query_vec = vectorizer.transform([query])
        similarities = cosine_similarity(query_vec, tfidf_matrix)[0]
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        results = []
        for idx in top_indices:
            if similarities[idx] > 0.1:
                results.append({
                    'answer': problems[idx]['answer'][:200],
                    'domain': problems[idx]['domain'],
                    'score': float(similarities[idx])
                })
        
        return results
    except:
        return []

# ===== Gemini API í˜¸ì¶œ =====
def analyze_image_with_gemini(image: Image.Image, question: str = ""):
    """ì´ë¯¸ì§€ ë¶„ì„ ë° ë‹µë³€ ìƒì„±"""
    if not GEMINI_API_KEY:
        return None, "âŒ API Key ì„¤ì • í•„ìš”í•©ë‹ˆë‹¤. Streamlit Cloudì˜ Secretsì—ì„œ ì„¤ì •í•˜ì„¸ìš”."
    
    try:
        model = genai.GenerativeModel(GEMINI_MODEL)
        
        prompt = f"""ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  í•™ìŠµì„ ë•ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

{f'ì¶”ê°€ ì§ˆë¬¸: {question}' if question else ''}

ë‹¤ìŒ í¬ë§·ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
1. ğŸ“Œ ì´ë¯¸ì§€ì—ì„œ ì¸ì‹ëœ ë‚´ìš©
2. ğŸ“š í•µì‹¬ ê°œë… ì„¤ëª…
3. ğŸ’¡ í•™ìŠµ íŒ"""
        
        response = model.generate_content([image, prompt])
        return response.text, None
    except Exception as e:
        error_msg = str(e)
        if "Quota exceeded" in error_msg:
            return None, "âš ï¸ API í• ë‹¹ëŸ‰ ì´ˆê³¼. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
        elif "401" in error_msg or "API key" in error_msg:
            return None, "âŒ API Key ì˜¤ë¥˜. Streamlit Cloudì˜ Secrets ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."
        return None, f"âŒ ì˜¤ë¥˜: {error_msg[:100]}"

# ===== Streamlit UI =====
st.set_page_config(page_title="Rubics", layout="wide", initial_sidebar_state="collapsed")

# CSS ìŠ¤íƒ€ì¼ (ëª¨ë°”ì¼ ìµœì í™”)
st.markdown("""
<style>
    /* ì—¬ë°± ìµœì†Œí™” */
    .main { padding: 0.5rem; }
    .stContainer { max-width: 100%; }
    
    /* ì±„íŒ… ìŠ¤íƒ€ì¼ */
    .chat-message {
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 0.5rem;
        font-size: 0.95rem;
    }
    .user-message {
        background-color: #e3f2fd;
        text-align: right;
    }
    .ai-message {
        background-color: #f5f5f5;
        text-align: left;
    }
    
    /* ëª¨ë°”ì¼ ìµœì í™” */
    @media (max-width: 768px) {
        .main { padding: 0.25rem; }
        .stMarkdown { font-size: 0.9rem; }
        .stButton > button { width: 100%; padding: 0.5rem; }
        .stTextInput > div > div > input { font-size: 1rem; }
        .stFileUploader { padding: 0.5rem; }
    }
</style>
""", unsafe_allow_html=True)

# ===== í—¤ë” =====
st.title("ğŸ“š Rubics")
st.markdown("**ì´ë¯¸ì§€ë¡œ ë°°ìš°ëŠ” AI í•™ìŠµ ë„ìš°ë¯¸**")

# ===== ì„¸ì…˜ ìƒíƒœ =====
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "current_image" not in st.session_state:
    st.session_state.current_image = None

# ===== ì´ë¯¸ì§€ ì—…ë¡œë“œ =====
st.subheader("ğŸ“¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ")

uploaded_file = st.file_uploader(
    "ë¬¸ì œ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
    type=["jpg", "jpeg", "png", "gif", "webp"],
    label_visibility="collapsed"
)

if uploaded_file:
    # ì´ë¯¸ì§€ ì €ì¥ ë° í‘œì‹œ
    image = Image.open(uploaded_file)
    st.session_state.current_image = image
    
    col1, col2 = st.columns([2, 1])
    with col1:
        st.image(image, use_column_width=True, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€")

# ===== ì±„íŒ… ì˜ì—­ =====
st.subheader("ğŸ’¬ ì§ˆë¬¸ ë° ë‹µë³€")

# ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
chat_container = st.container()
with chat_container:
    for i, msg in enumerate(st.session_state.chat_history):
        if msg["role"] == "user":
            st.markdown(f"""
            <div class='chat-message user-message'>
                <strong>ğŸ‘¤ You:</strong><br>{msg['content']}
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class='chat-message ai-message'>
                <strong>ğŸ¤– Rubics:</strong><br>{msg['content']}
            </div>
            """, unsafe_allow_html=True)

# ===== ì…ë ¥ ì˜ì—­ =====
st.divider()

# í…ìŠ¤íŠ¸ ì…ë ¥ (ì§ˆë¬¸)
user_question = st.text_input(
    "ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”",
    placeholder="ì˜ˆ: ì´ ë¬¸ì œëŠ” ì–´ë–»ê²Œ í’€ì–´?",
    label_visibility="collapsed"
)

# Enter ëˆ„ë¥´ë©´ ìë™ ë¶„ì„
if user_question or st.session_state.current_image:
    if st.session_state.current_image and user_question:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_history.append({
            "role": "user",
            "content": user_question
        })
        
        # AI ë¶„ì„
        with st.spinner("ğŸ” ë¶„ì„ ì¤‘..."):
            answer, error = analyze_image_with_gemini(
                st.session_state.current_image,
                user_question
            )
        
        if error:
            st.error(error)
        else:
            # AI ì‘ë‹µ ì¶”ê°€
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": answer
            })
            
            # ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰
            problems = load_master_answers()
            if problems:
                vectorizer, tfidf_matrix = build_problem_index(problems)
                similar = search_similar_problems(user_question, problems, vectorizer, tfidf_matrix)
                
                if similar:
                    st.info("ğŸ“š **ìœ ì‚¬ ë¬¸ì œ**")
                    for i, prob in enumerate(similar, 1):
                        st.write(f"{i}. [{prob['domain']}] {prob['answer']}")
        
        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()

# ===== ì‚¬ì´ë“œë°”: ì •ë³´ =====
with st.sidebar:
    st.markdown("### â„¹ï¸ ì •ë³´")
    st.markdown("""
    **Rubics**ëŠ” AI ê¸°ë°˜ í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
    
    - ğŸ“¸ ì´ë¯¸ì§€ë¡œ ë¬¸ì œ ë¶„ì„
    - ğŸ¤– AIê°€ ì„¤ëª…í•´ì¤ë‹ˆë‹¤
    - ğŸ“š ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ
    
    **ì‚¬ìš©ë²•:**
    1. ë¬¸ì œ ì‚¬ì§„ ì—…ë¡œë“œ
    2. ì§ˆë¬¸ ì…ë ¥
    3. Enter ëˆ„ë¥´ê¸°
    4. ë‹µë³€ ë°›ê¸°!
    """)
    
    st.divider()
    
    if st.button("ğŸ—‘ï¸ ì±„íŒ… ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.chat_history = []
        st.session_state.current_image = None
        st.rerun()

# ===== í•˜ë‹¨ ì •ë³´ =====
st.divider()
st.caption("ğŸ”’ API KeyëŠ” ì•ˆì „í•˜ê²Œ ë³´ê´€ë©ë‹ˆë‹¤. | Powered by Google Gemini")
