# =========================================================
# Qube ëª¨ë°”ì¼ ì•± MVP - ë¬¸ì œ ê¸°ë°˜ í•™ìŠµ í”Œë«í¼
# =========================================================
# í•µì‹¬ ê¸°ëŠ¥:
# 1. ì´ë¯¸ì§€ ì§ˆë¬¸ â†’ Gemini ë‹µë³€
# 2. ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰ (ORB/SIFT + íŠ¹ì„± ê¸°ë°˜ ë§¤ì¹­)
# 3. ë‹µë³€ í˜•íƒœ ì„ íƒ (ê°„ë‹¨/ìì„¸í•¨)
# 4. ë§ì¶¤í˜• í•™ìŠµ ì½˜í…ì¸  ìš”ì•½
# 5. ë³µìŠµ ìŠ¤ì¼€ì¤„ ì•Œë¦¼ (Spaced Repetition)
#
# ëª¨ë¸: Gemini (ì´ë¯¸ì§€ ë¶„ì„)
# ì¼ë°˜: YOLOv11 (ë¬¼ì²´ ì¸ì‹)
# í”„ë¦¬ë¯¸ì—„: SAM3 (ë§¤ì§ ì§€ìš°ê°œ, ì˜¤ë‹µë…¸íŠ¸)
# =========================================================

import sys
import subprocess
from pathlib import Path
import os
import json
import pickle
from datetime import datetime, timedelta
import numpy as np
import pandas as pd
from typing import List, Dict, Tuple, Optional
from PIL import Image
import io
import base64
import hashlib

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv(Path(__file__).parent / ".env")
except ImportError:
    # dotenvê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ .env íŒŒì¼ ì½ê¸°
    env_path = Path(__file__).parent / ".env"
    if env_path.exists():
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()

# OpenCV ì•ˆì „ import
try:
    import cv2
    HAS_CV2 = True
except ImportError:
    HAS_CV2 = False
    print("âš ï¸ OpenCVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ íŠ¹ì„± ê²€ìƒ‰ì´ ì œí•œë©ë‹ˆë‹¤.")

# ===== íŒ¨í‚¤ì§€ ìë™ ì„¤ì¹˜ =====
def pip_install(pkgs):
    if not pkgs:
        return
    cmd = [sys.executable, "-m", "pip", "install", "-q"] + pkgs
    try:
        subprocess.check_call(cmd)
    except Exception as e:
        print(f"âš ï¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹¤íŒ¨: {e}")

packages_needed = []
try:
    import streamlit
except:
    packages_needed.append("streamlit")
try:
    import google.generativeai
except:
    packages_needed.append("google-generativeai")
try:
    import sklearn
except:
    packages_needed.append("scikit-learn")
if not HAS_CV2:
    packages_needed.append("opencv-python")
try:
    from PIL import Image
except:
    packages_needed.append("pillow")

if packages_needed:
    print(f"ğŸ“¦ ì„¤ì¹˜ ì¤‘: {packages_needed}")
    pip_install(packages_needed)

import streamlit as st
import google.generativeai as genai
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


# ===== ê¸°ë³¸ ì„¤ì • =====
class Config:
    # ë°ì´í„° ê²½ë¡œ
    DATA_ROOT = Path(r"D:\Users\Qube\0. ë°ì´í„°")
    ANALYSIS_DIR = DATA_ROOT / "1. ë¶„ì„"
    SAMPLING_DIR = DATA_ROOT / "2. ìƒ˜í”Œë§"
    TRAINING_POOL_DIR = DATA_ROOT / "3. í•™ìŠµ í›„ë³´ í’€"
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    OUTPUT_DIR = Path(r"D:\Users\ì¥ìš°ì§„\dev26\qube_out_mvp")
    OUTPUT_DIR.mkdir(exist_ok=True)
    
    # Gemini API (Streamlit secrets > í™˜ê²½ë³€ìˆ˜ ìˆœì„œë¡œ ì½ê¸°)
    @staticmethod
    def get_api_key():
        # 1ìˆœìœ„: Streamlit secrets (í´ë¼ìš°ë“œ ë°°í¬ìš©)
        try:
            if "gemini_api_key" in st.secrets:
                return st.secrets["gemini_api_key"]
        except:
            pass
        
        # 2ìˆœìœ„: í™˜ê²½ë³€ìˆ˜ (ë¡œì»¬ ê°œë°œìš©)
        api_key = os.environ.get("GEMINI_API_KEY_wj", "")
        if api_key:
            return api_key
        
        return ""
    
    GEMINI_API_KEY = get_api_key.__func__()
    
    # Gemini ëª¨ë¸ ì„¤ì •
    # ì§€ì›í•˜ëŠ” ëª¨ë¸: gemini-2.0-flash, gemini-2.5-flash, gemini-pro ë“±
    GEMINI_MODEL = "gemini-2.0-flash"
    
    # ê¸°ë³¸ê°’
    DEFAULT_PORT = 8501
    MAX_SIMILAR_PROBLEMS = 5


# Gemini ì´ˆê¸°í™”
if Config.GEMINI_API_KEY:
    try:
        genai.configure(api_key=Config.GEMINI_API_KEY)
    except Exception as e:
        print(f"âš ï¸ Gemini ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
else:
    st.warning("âš ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì •ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


# ===== ë°ì´í„° ë¡œë” =====
class DataManager:
    """ë¶„ì„, ìƒ˜í”Œë§, í•™ìŠµ ë°ì´í„° ë¡œë“œ ë° ê´€ë¦¬"""
    
    def __init__(self):
        self.problems = []
        self.metadata = {}
        self._load_data()
    
    def _load_data(self):
        """CSV ë° ì´ë¯¸ì§€ ë°ì´í„° ë¡œë“œ - ë§ˆìŠ¤í„° ë‹µë³€ í¬í•¨"""
        # 1. decoded_messagesì—ì„œ ë§ˆìŠ¤í„° ë‹µë³€ ë¡œë“œ
        try:
            decoded_dir = Config.ANALYSIS_DIR / "ë°ì´í„°ë¶„ì„_ìµœì¢…" / "decoded_messages"
            if decoded_dir.exists():
                decoded_files = sorted(decoded_dir.glob("decoded_messages_part*.csv"))
                if decoded_files:
                    dfs = []
                    for f in decoded_files:
                        df = pd.read_csv(f, encoding='utf-8-sig')
                        dfs.append(df)
                    all_decoded = pd.concat(dfs, ignore_index=True)
                    
                    # ë¬¸ì œë³„ë¡œ ë§ˆìŠ¤í„° ë‹µë³€ ì¶”ì¶œ
                    self.problems = []
                    for qid, group in all_decoded.groupby('QM_QST_NO'):
                        master_msgs = group[group['speaker_role'] == 'master']
                        student_msgs = group[group['speaker_role'] == 'student']
                        
                        problem = {
                            'id': str(qid),
                            'QM_QST_NO': qid,
                            'DomName': group['DomName'].iloc[0] if len(group) > 0 else '',
                            'SubName': group['SubName'].iloc[0] if len(group) > 0 else '',
                            'class': group['class_value'].iloc[0] if len(group) > 0 else '',
                            'master_answer': ' '.join(master_msgs['qst_text_decoded'].tolist()) if len(master_msgs) > 0 else '',
                            'student_question': ' '.join(student_msgs['qst_text_decoded'].tolist()) if len(student_msgs) > 0 else '',
                            'has_image': group['has_image'].iloc[0] if len(group) > 0 else False,
                        }
                        if problem['master_answer']:  # ë§ˆìŠ¤í„° ë‹µë³€ì´ ìˆëŠ” ê²½ìš°ë§Œ
                            self.problems.append(problem)
                    
                    print(f"âœ“ ë§ˆìŠ¤í„° ë‹µë³€: {len(self.problems)}ê°œ ë¬¸ì œ ë¡œë“œë¨ (decoded_messagesì—ì„œ)")
                else:
                    print(f"âš ï¸ decoded_messages í´ë”ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {decoded_dir}")
                    self._create_sample_data()
            else:
                print(f"âš ï¸ decoded_messages í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {decoded_dir}")
                self._create_sample_data()
        except Exception as e:
            print(f"âš ï¸ ë§ˆìŠ¤í„° ë‹µë³€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self._create_sample_data()
        
        # 2. ë¶„ì„ ë°ì´í„° (ë©”íƒ€ë°ì´í„°)
        try:
            analysis_files = list(Config.ANALYSIS_DIR.glob("ë°ì´í„°ë¶„ì„_ìµœì¢…/*.csv"))
            if analysis_files:
                self.analysis_data = pd.concat([
                    pd.read_csv(f, encoding='utf-8-sig') 
                    for f in analysis_files
                ], ignore_index=True)
                print(f"âœ“ ë¶„ì„ ë©”íƒ€ë°ì´í„°: ë¡œë“œë¨")
        except Exception as e:
            print(f"âš ï¸ ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 3. ìƒ˜í”Œë§ ë°ì´í„° (ëŒ€í‘œ ì˜ˆì‹œ)
        try:
            sampling_files = list(Config.SAMPLING_DIR.glob("*.csv"))
            if sampling_files:
                self.sampling_data = pd.concat([
                    pd.read_csv(f, encoding='utf-8-sig')
                    for f in sampling_files
                ], ignore_index=True)
                print(f"âœ“ ìƒ˜í”Œë§ ë°ì´í„°: ë¡œë“œë¨")
        except Exception as e:
            print(f"âš ï¸ ìƒ˜í”Œë§ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 4. í•™ìŠµ í›„ë³´ í’€ (YOLOv11, SAM3 ì „ìš©)
        try:
            pool_files = list(Config.TRAINING_POOL_DIR.glob("*.csv"))
            if pool_files:
                self.training_pool = pd.concat([
                    pd.read_csv(f, encoding='utf-8-sig')
                    for f in pool_files
                ], ignore_index=True)
                print(f"âœ“ í•™ìŠµ í›„ë³´ í’€: ë¡œë“œë¨")
        except Exception as e:
            print(f"âš ï¸ í•™ìŠµ í›„ë³´ í’€ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _create_sample_data(self):
        """ë”ë¯¸ ìƒ˜í”Œ ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)"""
        self.problems = [
            {
                'id': f'problem_{i}',
                'content': f'Sample problem {i}. This is a test problem for demonstrating the system.',
                'category': f'Category {i % 3}',
                'difficulty': ['easy', 'medium', 'hard'][i % 3]
            }
            for i in range(5)  # ìµœì†Œ 5ê°œì˜ ìƒ˜í”Œ ë°ì´í„°
        ]
        print(f"âš ï¸ ë”ë¯¸ ë°ì´í„°ë¡œ {len(self.problems)}ê°œ ìƒ˜í”Œ ìƒì„±ë¨")
    
    def get_all_problems(self) -> List[Dict]:
        """ëª¨ë“  ë¬¸ì œ ë°˜í™˜"""
        return self.problems
    
    def get_problem_by_id(self, problem_id: str) -> Optional[Dict]:
        """IDë¡œ ë¬¸ì œ ì¡°íšŒ"""
        for p in self.problems:
            if p.get('id') == problem_id:
                return p
        return None


# ===== ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰ (ORB/SIFT) =====
class SimilarProblemFinder:
    """ì´ë¯¸ì§€ íŠ¹ì„± ê¸°ë°˜ + í…ìŠ¤íŠ¸ ê¸°ë°˜ ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰"""
    
    def __init__(self, data_manager: DataManager):
        self.data_manager = data_manager
        self.orb = cv2.ORB_create(nfeatures=500) if HAS_CV2 else None
        self.sift = cv2.SIFT_create() if HAS_CV2 else None
        # TfidfVectorizerë¥¼ ë” ì•ˆì „í•˜ê²Œ ì„¤ì • (min_df=1, stop_words ì œê±°)
        self.tfidf = TfidfVectorizer(
            max_features=200,
            min_df=1,
            max_df=0.95,
            ngram_range=(1, 1),
            lowercase=True
        )
        self._build_text_index()
    
    def _build_text_index(self):
        """ë¬¸ì œ ë° ë§ˆìŠ¤í„° ë‹µë³€ ê¸°ë°˜ TF-IDF ìƒ‰ì¸ êµ¬ì¶•"""
        problems = self.data_manager.get_all_problems()
        
        # ë§ˆìŠ¤í„° ë‹µë³€ + í•™ìƒ ì§ˆë¬¸ í•©ì¹˜ê¸°
        texts = []
        for p in problems:
            # ë§ˆìŠ¤í„° ë‹µë³€ì´ ìš°ì„ ìˆœìœ„
            text = str(p.get('master_answer', '')) or str(p.get('student_question', ''))
            if not text:
                text = str(p.get('content', ''))  # í´ë°±
            texts.append(text)
        
        # ê³µë°±ì´ ì•„ë‹Œ í…ìŠ¤íŠ¸ë§Œ í•„í„°ë§
        texts = [t.strip() for t in texts if t.strip()]
        
        if texts and len(texts) > 1:
            try:
                self.tfidf_matrix = self.tfidf.fit_transform(texts)
                print(f"âœ“ TF-IDF ìƒ‰ì¸: {len(texts)}ê°œ ë¬¸ì œ ìƒ‰ì¸ë¨ (ë§ˆìŠ¤í„° ë‹µë³€ í¬í•¨)")
            except ValueError as e:
                # empty vocabulary ì—ëŸ¬ ì²˜ë¦¬
                print(f"âš ï¸ TF-IDF ìƒ‰ì¸ êµ¬ì¶• ì‹¤íŒ¨: {e}")
                print(f"   ë¡œë“œëœ í…ìŠ¤íŠ¸: {len(texts)}ê°œ (ìµœì†Œ 2ê°œ í•„ìš”)")
                self.tfidf_matrix = None
        else:
            print(f"âš ï¸ í…ìŠ¤íŠ¸ ë°ì´í„° ë¶€ì¡±: {len(texts)}ê°œ (ìµœì†Œ 2ê°œ í•„ìš”)")
            self.tfidf_matrix = None
    
    def find_similar_by_text(self, query: str, top_k: int = 5) -> List[Dict]:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰ (ë§ˆìŠ¤í„° ë‹µë³€ í¬í•¨)"""
        if self.tfidf_matrix is None:
            return []
        
        try:
            query_vec = self.tfidf.transform([query])
            scores = cosine_similarity(query_vec, self.tfidf_matrix)[0]
            top_indices = np.argsort(scores)[-top_k:][::-1]
            
            problems = self.data_manager.get_all_problems()
            results = []
            
            for idx in top_indices:
                if scores[idx] > 0.05:  # ìœ ì‚¬ë„ ì„ê³„ê°’ ì¡°ì •
                    problem = problems[idx]
                    results.append({
                        'id': problem.get('id', ''),
                        'QM_QST_NO': problem.get('QM_QST_NO', ''),
                        'DomName': problem.get('DomName', ''),
                        'SubName': problem.get('SubName', ''),
                        'class': problem.get('class', ''),
                        'similarity': float(scores[idx]),
                        'master_answer': problem.get('master_answer', ''),
                        'student_question': problem.get('student_question', ''),
                    })
            
            return results
        except Exception as e:
            print(f"âš ï¸ ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def find_similar_by_image(self, image: np.ndarray, top_k: int = 5) -> List[Dict]:
        """ì´ë¯¸ì§€ ê¸°ë°˜ ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰ (ORB/SIFT)"""
        if not HAS_CV2:
            return {'status': 'cv2_not_available', 'message': 'OpenCVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}
        
        try:
            # ì—…ë¡œë“œ ì´ë¯¸ì§€ì—ì„œ íŠ¹ì„± ì¶”ì¶œ
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image
            
            # ORB íŠ¹ì„± (ë¹ ë¦„)
            kp_orb, des_orb = self.orb.detectAndCompute(gray, None)
            # SIFT íŠ¹ì„± (ì •í™•ë„)
            kp_sift, des_sift = self.sift.detectAndCompute(gray, None)
            
            # íŠ¹ì„±ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ë§¤ì¹­ ìˆ˜í–‰
            if des_orb is not None and len(kp_orb) > 3:
                return {
                    'orb_keypoints': len(kp_orb),
                    'sift_keypoints': len(kp_sift) if des_sift is not None else 0,
                    'status': 'success'
                }
            else:
                return {'status': 'no_features_found'}
        except Exception as e:
            return {'status': 'error', 'message': str(e)}
    
    def find_similar_combined(self, image: np.ndarray, query_text: str = "", top_k: int = 5) -> List[Dict]:
        """ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ê²°í•© ê²€ìƒ‰"""
        results = []
        
        # í…ìŠ¤íŠ¸ ê¸°ë°˜
        if query_text:
            text_results = self.find_similar_by_text(query_text, top_k)
            problems = self.data_manager.get_all_problems()
            for idx, score in text_results:
                if idx < len(problems):
                    problems[idx]['similarity_score'] = score
                    problems[idx]['method'] = 'text_based'
                    results.append(problems[idx])
        
        return results[:top_k]


# ===== Gemini í†µí•© =====
class GeminiIntegration:
    """Geminië¥¼ ì´ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„ ë° ë‹µë³€"""
    
    @staticmethod
    def analyze_image_question(image: Image.Image, question: str, 
                                answer_style: str = "simple") -> Dict:
        """ì´ë¯¸ì§€ + ì§ˆë¬¸ ë¶„ì„"""
        if not Config.GEMINI_API_KEY:
            return {"error": "Gemini API ë¯¸ì„¤ì •"}
        
        try:
            model = genai.GenerativeModel(Config.GEMINI_MODEL)
            
            # ë‹µë³€ ìŠ¤íƒ€ì¼ì— ë§ê²Œ í”„ë¡¬í”„íŠ¸ ì¡°ì •
            style_prompt = {
                'simple': "ê°„ë‹¨ëª…ë£Œí•˜ê²Œ 1-2ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.",
                'detailed': "ìì„¸í•˜ê³  ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ì„¸ìš”. ê³¼ì •ì„ í¬í•¨í•˜ì„¸ìš”.",
                'step_by_step': "1ë‹¨ê³„, 2ë‹¨ê³„, 3ë‹¨ê³„ í˜•ì‹ìœ¼ë¡œ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ì„¸ìš”.",
                'concept': "í•µì‹¬ ê°œë…ì„ ë¨¼ì € ì„¤ëª…í•œ í›„ ì´ ë¬¸ì œì— ì–´ë–»ê²Œ ì ìš©ë˜ëŠ”ì§€ ì„¤ëª…í•˜ì„¸ìš”."
            }
            
            prompt = f"""{style_prompt.get(answer_style, style_prompt['simple'])}
            
ì‚¬ìš©ì ì§ˆë¬¸: {question}

ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ìœ„ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”."""
            
            response = model.generate_content([image, prompt])
            
            return {
                "status": "success",
                "answer": response.text,
                "style": answer_style,
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            error_str = str(e)
            
            # í• ë‹¹ëŸ‰ ì´ˆê³¼ ì˜¤ë¥˜ ê°ì§€
            if "Quota exceeded" in error_str or "quota" in error_str.lower():
                return {
                    "status": "quota_exceeded",
                    "error_message": "âŒ Gemini API ë¬´ë£Œ í• ë‹¹ëŸ‰ì´ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤. Google Cloud Consoleì—ì„œ ê²°ì œ ì •ë³´ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
                }
            elif "API_KEY" in error_str or "api_key" in error_str.lower():
                return {
                    "status": "invalid_api_key",
                    "error_message": "âŒ API Keyê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì„¤ì • í˜ì´ì§€ì—ì„œ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”."
                }
            else:
                return {
                    "status": "error",
                    "error_message": f"âš ï¸ API ì˜¤ë¥˜: {error_str[:100]}"
                }
    
    @staticmethod
    def summarize_learning_content(interactions: List[Dict]) -> str:
        """í•™ìŠµ ìƒí˜¸ì‘ìš©ì„ ë‹¨ì¼ í˜ì´ì§€ë¡œ ìš”ì•½"""
        if not Config.GEMINI_API_KEY:
            return "API ë¯¸ì„¤ì •"
        
        try:
            model = genai.GenerativeModel(Config.GEMINI_MODEL)
            
            interaction_text = "\n\n".join([
                f"Q: {i.get('question', '')}\nA: {i.get('answer', '')}"
                for i in interactions
            ])
            
            prompt = f"""ë‹¤ìŒ í•™ìŠµ ë‚´ìš©ì„ í•œ í˜ì´ì§€ë¡œ ìš”ì•½í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì‚¬ìš©:
- í•µì‹¬ ê°œë…
- ì£¼ìš” ê³µì‹/ì •ë¦¬
- ì‹¤ì „ íŒ
- ë³µìŠµ í¬ì¸íŠ¸

í•™ìŠµ ë‚´ìš©:
{interaction_text}"""
            
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            error_str = str(e)
            
            if "Quota exceeded" in error_str or "quota" in error_str.lower():
                return """### âŒ API í• ë‹¹ëŸ‰ ì´ˆê³¼

Gemini API ë¬´ë£Œ í• ë‹¹ëŸ‰ì´ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.

**í•´ê²° ë°©ë²•:**
1. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„ (í• ë‹¹ëŸ‰ ìë™ ë¦¬ì…‹)
2. [Google Cloud Console](https://console.cloud.google.com)ì—ì„œ ê²°ì œ ì •ë³´ ì¶”ê°€

**í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸:** `gemini-2.0-flash`"""
            else:
                return f"""### âš ï¸ ìš”ì•½ ìƒì„± ì‹¤íŒ¨

**ì˜¤ë¥˜:** {error_str[:200]}

ì„¤ì •ì—ì„œ API Keyë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”."""


# ===== ë³µìŠµ ìŠ¤ì¼€ì¤„ (Spaced Repetition) =====
class ReviewScheduler:
    """ë³µìŠµ ì£¼ê¸° ê´€ë¦¬ ë° ì•Œë¦¼"""
    
    # ì—¥ê²”ë§Œì˜ ê°„ê²© ë°˜ë³µ ê³¡ì„ 
    INTERVALS = [1, 3, 7, 14, 30]  # ì¼ ë‹¨ìœ„
    
    def __init__(self, storage_dir: Path):
        self.storage_dir = storage_dir
        self.storage_dir.mkdir(exist_ok=True)
        self.review_history = self._load_history()
    
    def _load_history(self) -> Dict:
        """ë³µìŠµ ê¸°ë¡ ë¡œë“œ"""
        history_file = self.storage_dir / "review_history.json"
        if history_file.exists():
            with open(history_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _save_history(self):
        """ë³µìŠµ ê¸°ë¡ ì €ì¥"""
        history_file = self.storage_dir / "review_history.json"
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(self.review_history, f, ensure_ascii=False, indent=2)
    
    def record_problem(self, problem_id: str, solved: bool = True):
        """ë¬¸ì œ í’€ì´ ê¸°ë¡"""
        if problem_id not in self.review_history:
            self.review_history[problem_id] = {
                'attempts': 0,
                'correct': 0,
                'last_reviewed': None,
                'next_review': datetime.now().isoformat()
            }
        
        record = self.review_history[problem_id]
        record['attempts'] += 1
        if solved:
            record['correct'] += 1
        record['last_reviewed'] = datetime.now().isoformat()
        
        # ë‹¤ìŒ ë³µìŠµ ì¼ì‹œ ê³„ì‚°
        correct_count = record['correct']
        if correct_count < len(self.INTERVALS):
            next_date = datetime.now() + timedelta(days=self.INTERVALS[correct_count])
            record['next_review'] = next_date.isoformat()
        
        self._save_history()
        return record
    
    def get_review_due(self) -> List[str]:
        """ë³µìŠµ ê¸°í•œì´ ëœ ë¬¸ì œë“¤"""
        now = datetime.now()
        due = []
        
        for problem_id, record in self.review_history.items():
            next_review = datetime.fromisoformat(record['next_review'])
            if next_review <= now:
                due.append(problem_id)
        
        return due[:10]  # ìµœëŒ€ 10ê°œ


# ===== Streamlit UI =====
def main():
    """ë©”ì¸ ì•± ì¸í„°í˜ì´ìŠ¤"""
    st.set_page_config(
        page_title="Qube í•™ìŠµ MVP",
        page_icon="ğŸ“š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ëª¨ë°”ì¼ ë°˜ì‘í˜• ìŠ¤íƒ€ì¼
    st.markdown("""
    <style>
    /* ëª¨ë°”ì¼ ìµœì í™” */
    @media (max-width: 768px) {
        .main { padding: 0.5rem !important; }
        .block-container { padding: 0.5rem !important; max-width: 100% !important; }
        h1 { font-size: 1.5rem !important; }
        h2 { font-size: 1.2rem !important; }
        .stButton > button { width: 100%; padding: 0.5rem !important; font-size: 0.9rem; }
    }
    
    /* ì¼ë°˜ ìŠ¤íƒ€ì¼ */
    .stButton > button {
        padding: 0.5rem 1rem !important;
        font-size: 1rem;
    }
    
    /* íŒŒì¼ ì—…ë¡œë” ìµœì í™” */
    .stFileUploader {
        width: 100% !important;
    }
    
    /* ì…ë ¥ í•„ë“œ */
    .stTextInput input, .stTextArea textarea {
        font-size: 1rem !important;
    }
    
    /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
    .stMetric {
        background: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
    }
    
    /* ìµìŠ¤íŒ¬ë” */
    .streamlit-expanderHeader {
        font-size: 1rem !important;
    }
    </style>
    """, unsafe_allow_html=True)
    
    st.title("ğŸ“š Qube - AI ë¬¸ì œ ê¸°ë°˜ í•™ìŠµ í”Œë«í¼")
    st.markdown("*Gemini Ã— YOLOv11 Ã— SAM3 ê¸°ë°˜ ë§ì¶¤í˜• í•™ìŠµ*")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
    col1, col2 = st.columns(2)
    
    with col1:
        if not HAS_CV2:
            st.warning("âš ï¸ OpenCVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ íŠ¹ì„± ê²€ìƒ‰ì´ ì œí•œë©ë‹ˆë‹¤.")
        else:
            st.success("âœ“ OpenCV ì„¤ì¹˜ë¨")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'data_manager' not in st.session_state:
        st.session_state.data_manager = DataManager()
    
    with col2:
        problems_count = len(st.session_state.data_manager.get_all_problems())
        if problems_count > 0:
            st.success(f"âœ“ {problems_count}ê°œ ë¬¸ì œ ë¡œë“œë¨")
        else:
            st.error("âŒ ë¡œë“œëœ ë¬¸ì œ ì—†ìŒ")
    
    if 'review_scheduler' not in st.session_state:
        st.session_state.review_scheduler = ReviewScheduler(Config.OUTPUT_DIR)
    if 'similar_finder' not in st.session_state:
        st.session_state.similar_finder = SimilarProblemFinder(st.session_state.data_manager)
    if 'learning_history' not in st.session_state:
        st.session_state.learning_history = []
    
    # ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜
    with st.sidebar:
        st.markdown("## ğŸ¯ ê¸°ëŠ¥ ì„ íƒ")
        
        mode = st.radio(
            "ì„ íƒí•˜ì„¸ìš”",
            [
                "â“ ì´ë¯¸ì§€ ì§ˆë¬¸ ë‹µë³€",
                "ğŸ” ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰",
                "ğŸ“ í•™ìŠµ ì½˜í…ì¸  ìš”ì•½",
                "ğŸ”„ ë³µìŠµ ìŠ¤ì¼€ì¤„",
                "âš™ï¸ ì„¤ì •"
            ],
            label_visibility="collapsed"
        )
        
        st.divider()
        st.caption("ğŸ“± ëª¨ë°”ì¼ íŒ: ìƒë‹¨ í–„ë²„ê±° ë©”ë‰´ë¡œ ë„¤ë¹„ê²Œì´ì…˜")
    
    # ===== 1) ì´ë¯¸ì§€ ì§ˆë¬¸ ë‹µë³€ =====
    if mode == "â“ ì´ë¯¸ì§€ ì§ˆë¬¸ ë‹µë³€":
        st.header("ì´ë¯¸ì§€ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸°")
        st.write("ì´ë¯¸ì§€ì—ì„œ ë¬¸ì œë¥¼ ë³´ì´ê³ , ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ Geminiê°€ ë‹µë³€í•´ì¤ë‹ˆë‹¤.")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ì´ë¯¸ì§€ ì„ íƒ** (JPG, PNG, WEBP ì§€ì›, ìµœëŒ€ 200MB)")
            uploaded_image = st.file_uploader(
                "ì´ë¯¸ì§€ ì—…ë¡œë“œ",
                type=['jpg', 'jpeg', 'png', 'webp'],
                label_visibility="collapsed"
            )
        
        with col2:
            st.write("**ë‹µë³€ ë°©ì‹ ì„ íƒ**")
            answer_style = st.selectbox(
                "ìŠ¤íƒ€ì¼",
                ["simple", "detailed", "step_by_step", "concept"],
                format_func=lambda x: {
                    "simple": "ê°„ë‹¨í•œ ì„¤ëª…",
                    "detailed": "ìì„¸í•œ ì„¤ëª…",
                    "step_by_step": "ë‹¨ê³„ë³„ ì„¤ëª…",
                    "concept": "ê°œë… ì¤‘ì‹¬"
                }[x],
                label_visibility="collapsed"
            )
        
        question = st.text_area("ğŸ“ ì§ˆë¬¸ ì…ë ¥", placeholder="ë¬´ì—‡ì„ ë¬»ê³  ì‹¶ì€ê°€ìš”?", height=100)
        
        if uploaded_image and question:
            col_a, col_b = st.columns([1, 1])
            
            with col_a:
                image = Image.open(uploaded_image)
                st.image(image, caption="ğŸ“¸ ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)
            
            with col_b:
                if st.button("ğŸš€ ë‹µë³€ ìƒì„±", use_container_width=True):
                    if not Config.GEMINI_API_KEY:
                        st.error("âŒ API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì • í˜ì´ì§€ì—ì„œ API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                    else:
                        with st.spinner("ğŸ¤– Gemini ë¶„ì„ ì¤‘..."):
                            result = GeminiIntegration.analyze_image_question(
                                image, question, answer_style
                            )
                        
                        if result.get('status') == 'success':
                            st.success("âœ… ë‹µë³€ ì™„ë£Œ!")
                            st.markdown(f"**ë‹µë³€:**\n\n{result['answer']}")
                            
                            # í•™ìŠµ ê¸°ë¡ ì €ì¥
                            st.session_state.learning_history.append({
                                'timestamp': datetime.now().isoformat(),
                                'question': question,
                                'answer': result['answer'],
                                'style': answer_style
                            })
                            
                            # ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰
                            st.divider()
                            st.subheader("ğŸ” ìœ ì‚¬ ë¬¸ì œ")
                            with st.spinner("ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰ ì¤‘..."):
                                try:
                                    similar = st.session_state.similar_finder.find_similar_by_text(question)
                                except Exception as e:
                                    st.error(f"ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                                    similar = []
                            
                            if similar:
                                for i, prob in enumerate(similar[:Config.MAX_SIMILAR_PROBLEMS], 1):
                                    with st.expander(f"ğŸ“Œ ìœ ì‚¬ ë¬¸ì œ {i} - {prob['DomName']} (ìœ ì‚¬ë„: {prob['similarity']:.1%})"):
                                        st.write(f"**ê³¼ëª©:** {prob['DomName']} / {prob['SubName']}")
                                        st.write(f"**ë‚œì´ë„:** {prob['class']}")
                                        
                                        if prob['student_question']:
                                            st.write("**ğŸ“ í•™ìƒ ì§ˆë¬¸:**")
                                            st.write(prob['student_question'][:300] + "..." if len(prob['student_question']) > 300 else prob['student_question'])
                                        
                                        if prob['master_answer']:
                                            st.write("**ğŸ’¡ ë§ˆìŠ¤í„° ë‹µë³€:**")
                                            st.write(prob['master_answer'][:500] + "..." if len(prob['master_answer']) > 500 else prob['master_answer'])
                            else:
                                st.info("ìœ ì‚¬í•œ ë¬¸ì œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        else:
                            error_msg = result.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ')
                            error_status = result.get('status', 'error')
                            
                            if error_status == 'quota_exceeded':
                                st.error(error_msg)
                                st.markdown("""
                                ---
                                ### ğŸ“‹ í•´ê²° ë°©ë²•
                                
                                1. **ë‚´ì¼ ë‹¤ì‹œ ì‹œë„** - ë¬´ë£Œ í• ë‹¹ëŸ‰ì€ ë§¤ì¼ ìë™ ë¦¬ì…‹ë©ë‹ˆë‹¤
                                2. **ìœ ë£Œ API ì „í™˜** (ê¶Œì¥)
                                   - [Google Cloud Console](https://console.cloud.google.com) ì ‘ì†
                                   - ê²°ì œ ì •ë³´ ì¶”ê°€
                                   - í”„ë¡œì íŠ¸ ì„¤ì •ì—ì„œ ì²­êµ¬ í™œì„±í™”
                                   - ê·¸ëŸ¬ë©´ í›¨ì”¬ ë” ë†’ì€ í•œë„ ì‚¬ìš© ê°€ëŠ¥
                                
                                **í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸:** `gemini-2.0-flash`
                                """)
                            elif error_status == 'invalid_api_key':
                                st.error(error_msg)
                                st.info("âš™ï¸ ì„¤ì • íƒ­ì—ì„œ API Keyë¥¼ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                            else:
                                st.error(f"âŒ {error_msg}")
                                st.caption("ì„¤ì • íƒ­ì—ì„œ API Key ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                elif uploaded_image:
                    st.info("â“ ìœ„ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
                elif question:
                    st.info("ğŸ“¸ ìœ„ì— ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    
    # ===== 2) ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰ =====
    elif mode == "ğŸ” ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰":
        st.header("ìœ ì‚¬ ë¬¸ì œ ê²€ìƒ‰")
        
        search_type = st.radio("ê²€ìƒ‰ ë°©ì‹", ["ì´ë¯¸ì§€ ê¸°ë°˜", "í…ìŠ¤íŠ¸ ê¸°ë°˜"])
        
        if search_type == "ì´ë¯¸ì§€ ê¸°ë°˜":
            uploaded = st.file_uploader("ì´ë¯¸ì§€ ì„ íƒ", type=['jpg', 'jpeg', 'png'])
            if uploaded:
                image = Image.open(uploaded)
                st.image(image, use_container_width=True)
                
                if st.button("ğŸ” ìœ ì‚¬ ë¬¸ì œ ì°¾ê¸°"):
                    img_array = np.array(image)
                    results = st.session_state.similar_finder.find_similar_by_image(img_array)
                    st.json(results)
        
        else:
            query = st.text_area("ê²€ìƒ‰ì–´ ì…ë ¥")
            if query and st.button("ê²€ìƒ‰"):
                with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                    results = st.session_state.similar_finder.find_similar_by_text(query)
                
                if results:
                    st.success(f"âœ… ì°¾ì€ ë¬¸ì œ: {len(results)}ê°œ")
                    for i, prob in enumerate(results, 1):
                        with st.expander(f"ğŸ“Œ {i}. {prob['DomName']} - {prob['SubName']} (ìœ ì‚¬ë„: {prob['similarity']:.1%})"):
                            col1, col2 = st.columns(2)
                            with col1:
                                st.write(f"**ê³¼ëª© ë¶„ë¥˜:** {prob['DomName']}")
                                st.write(f"**ì„¸ë¶€:** {prob['SubName']}")
                                st.write(f"**ë‚œì´ë„:** {prob['class']}")
                            with col2:
                                st.write(f"**ì§ˆë¬¸ ID:** {prob['QM_QST_NO']}")
                                st.write(f"**ìœ ì‚¬ë„:** {prob['similarity']:.1%}")
                            
                            if prob['student_question']:
                                st.write("**ğŸ“ í•™ìƒ ì§ˆë¬¸:**")
                                st.write(prob['student_question'][:200] + "..." if len(prob['student_question']) > 200 else prob['student_question'])
                            
                            if prob['master_answer']:
                                st.write("**ğŸ’¡ ë§ˆìŠ¤í„° ë‹µë³€:**")
                                st.write(prob['master_answer'][:500] + "..." if len(prob['master_answer']) > 500 else prob['master_answer'])
                else:
                    st.warning("ìœ ì‚¬í•œ ë¬¸ì œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
    # ===== 3) í•™ìŠµ ì½˜í…ì¸  ìš”ì•½ =====
    elif mode == "ğŸ“ í•™ìŠµ ì½˜í…ì¸  ìš”ì•½":
        st.header("ì˜¤ëŠ˜ì˜ í•™ìŠµ ìš”ì•½")
        
        if st.session_state.learning_history:
            st.write(f"ğŸ“Š ì˜¤ëŠ˜ í’€ì´í•œ ë¬¸ì œ: {len(st.session_state.learning_history)}ê°œ")
            
            if st.button("ğŸ“„ ìš”ì•½ ìƒì„±"):
                with st.spinner("ìš”ì•½ ìƒì„± ì¤‘..."):
                    summary = GeminiIntegration.summarize_learning_content(
                        st.session_state.learning_history
                    )
                st.markdown(summary)
                
                # ì €ì¥ ë²„íŠ¼
                if st.button("ğŸ’¾ ìš”ì•½ ì €ì¥"):
                    filename = Config.OUTPUT_DIR / f"summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
                    filename.write_text(summary, encoding='utf-8')
                    st.success(f"âœ… ì €ì¥ë¨: {filename.name}")
        else:
            st.info("ì•„ì§ í’€ì´í•œ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ===== 4) ë³µìŠµ ìŠ¤ì¼€ì¤„ =====
    elif mode == "ğŸ”„ ë³µìŠµ ìŠ¤ì¼€ì¤„":
        st.header("ë³µìŠµ ìŠ¤ì¼€ì¤„")
        
        scheduler = st.session_state.review_scheduler
        due_problems = scheduler.get_review_due()
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ“š ì´ í•™ìŠµ", len(scheduler.review_history))
        with col2:
            st.metric("ğŸ”„ ë³µìŠµ ì˜ˆì •", len(due_problems))
        with col3:
            correct_count = sum(1 for r in scheduler.review_history.values() if r['correct'] > 0)
            st.metric("âœ… ì •ë‹µìœ¨", f"{correct_count}/{len(scheduler.review_history)}")
        
        if due_problems:
            st.warning("â° ë³µìŠµì´ í•„ìš”í•œ ë¬¸ì œë“¤")
            for pid in due_problems:
                st.write(f"- {pid}")
        else:
            st.success("ğŸ‰ ëª¨ë“  ë³µìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ===== 5) ì„¤ì • =====
    elif mode == "âš™ï¸ ì„¤ì •":
        st.header("âš™ï¸ ì„¤ì •")
        
        st.subheader("ğŸ”‘ API ì„¤ì •")
        st.write("Gemini API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        api_key = st.text_input(
            "API Key ì…ë ¥",
            type="password",
            placeholder="sk-... í˜•íƒœì˜ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            help="[Google AI Studio](https://aistudio.google.com/app/apikey)ì—ì„œ ë°œê¸‰ë°›ìœ¼ì„¸ìš”"
        )
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ’¾ ì €ì¥"):
                if api_key:
                    os.environ["GEMINI_API_KEY_wj"] = api_key
                    Config.GEMINI_API_KEY = api_key
                    st.success("âœ… API Key ì €ì¥ë¨")
                    st.rerun()
                else:
                    st.error("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        
        with col2:
            if st.button("í™•ì¸"):
                if Config.GEMINI_API_KEY:
                    try:
                        import google.generativeai as genai
                        genai.configure(api_key=Config.GEMINI_API_KEY)
                        model = genai.GenerativeModel(Config.GEMINI_MODEL)
                        st.success("âœ… API Key ìœ íš¨í•¨")
                    except Exception as e:
                        st.error(f"âŒ API ì˜¤ë¥˜: {str(e)[:100]}")
                else:
                    st.error("âŒ API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        st.divider()
        st.subheader("ğŸ“‹ ë¬´ë£Œ API í• ë‹¹ëŸ‰")
        
        st.markdown("""
        **Gemini API ë¬´ë£Œ í•œë„:**
        - ğŸ“Š ì¼ì¼ ìš”ì²­: 1,500ê°œ
        - â±ï¸ ë¶„ë‹¹ ìš”ì²­: 15ê°œ
        - ğŸ”¤ ë¶„ë‹¹ í† í°: 10ë§Œ ê°œ
        
        **í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ í•´ê²° ë°©ë²•:**
        1. **ë‚´ì¼ ë‹¤ì‹œ ì‹œë„** - ìë™ìœ¼ë¡œ ë¦¬ì…‹ë¨
        2. **ìœ ë£Œ API ì „í™˜** (ê¶Œì¥)
           - [Google Cloud Console](https://console.cloud.google.com) ì ‘ì†
           - ê²°ì œ ì •ë³´ ì¶”ê°€ ë° ì²­êµ¬ í™œì„±í™”
           - í›¨ì”¬ ë” ë†’ì€ í•œë„ ì‚¬ìš© ê°€ëŠ¥
        """)
        
        st.divider()
        st.subheader("ğŸ¤– ëª¨ë¸ ì •ë³´")
        
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸:**")
            st.code(Config.GEMINI_MODEL)
        
        with col2:
            st.write(f"**API ìƒíƒœ:**")
            if Config.GEMINI_API_KEY:
                st.success("âœ“ API Key ì„¤ì •ë¨")
            else:
                st.warning("âš ï¸ API Key ë¯¸ì„¤ì • (ìœ„ì—ì„œ ì„¤ì •í•˜ì„¸ìš”)")
        
        st.divider()
        st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        
        problems = st.session_state.data_manager.get_all_problems()
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ“š ë¡œë“œëœ ë¬¸ì œ", f"{len(problems)}ê°œ")
        
        with col2:
            tfidf_status = "âœ“" if st.session_state.similar_finder.tfidf_matrix is not None else "âœ—"
            st.metric("ğŸ“‘ ìƒ‰ì¸ ìƒíƒœ", tfidf_status)
        
        with col3:
            cv2_status = "âœ“" if HAS_CV2 else "âœ—"
            st.metric("ğŸ–¼ï¸ OpenCV", cv2_status)
        
        st.divider()
        st.subheader("ğŸ’¾ í•™ìŠµ ë°ì´í„°")
        
        learning_count = len(st.session_state.learning_history)
        review_count = len(st.session_state.review_scheduler.review_history)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("âœï¸ í’€ì´í•œ ë¬¸ì œ", learning_count)
        with col2:
            st.metric("ğŸ”„ ë³µìŠµ ê¸°ë¡", review_count)
        
        st.divider()
        st.subheader("ğŸ“ ì‹œìŠ¤í…œ ì •ë³´")
        
        with st.expander("ğŸ—‚ï¸ ë°ì´í„° ê²½ë¡œ"):
            st.code(str(Config.DATA_ROOT))
            st.code(str(Config.OUTPUT_DIR))
        
        # ë°ì´í„° ìƒíƒœ í™•ì¸
        if len(problems) == 0:
            st.info("""
            â„¹ï¸ **ì•„ì§ ë§ˆìŠ¤í„° ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**
            
            ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:
            1. ë°ì´í„° ê²½ë¡œê°€ ì¡´ì¬í•˜ëŠ”ê°€
            2. decoded_messages CSV íŒŒì¼ì´ ìˆëŠ”ê°€
            3. ìœ„ì—ì„œ API Keyë¥¼ ì„¤ì •í–ˆëŠ”ê°€
            
            í˜„ì¬ëŠ” í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°(5ê°œ)ë¡œ ë™ì‘í•©ë‹ˆë‹¤.
            """)


if __name__ == "__main__":
    main()
